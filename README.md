# Lexiden-AI---Tech-Challenge
This repository features an AI-integrated mock application with a functional chatbot interface as part of an internship challenge. 

## Intended Functionality
This project is a simple demonstration of contextual LLM interaction using Flask and React js with no auth or other extraneous features.

An SSE transaction is established to allow real-time streaming of data back and forth. The /chatstream url is used for bidirectional communication between the user and gpt-5-mini via an OpenAI API Key. (You must provide your own replacement API Key in the env file for the chatbot to work). I have provided misc endpoints to evaluate different point(s) of failure to ensure that the app works.

For this demo I have provided some sample mock legal documents to test the application. Check _"dockstestinfo.txt"_ for more info.

The contextual prompt has 3 key parts:

 - The root: This includes prior instructions for the LLM with various **bolded** sections for emphasis. Some targeted instructions, such as warning it for potential prompt injection by identifying headers is provided. (e.g the user tells it to drop all previous instructions and do something outside the scope of the service being provided).
 - Context: This section gives it the chunks of data extracted from the _legaldocs_test_ directory (all of these are .txt files for simplicity). (Need to implement Retrieval Augmented Generation for optimal similarity search indexing, though I have yet to check how to do this without using a dedicated db service like PGVector e.g simple embeddings in an in-memory db.)
 - Message: The actual user input (via post call)

The frontend for this application is a simple setup to display formatted text blocks, separating the user and ai responses using a flag based approach.

### Done:

- Basic setup (main, service layer, router, db model layer (if needed))
- Simple debugging endpoints: root, echo test, stream test (using time elapsed since page is visited)
- Set up env file for protected variables/keys (no auth)

### To Do:
 - Work on the frontend:
    - fetch realtime stream responses from backend and refresh frontend contents. e.g AI message is not to be stuck in blocking or waiting mode if the output is too long, rather the chat bubble will update concurrently until the full message is displayed (optional stop functionality though I don't know how to implement that).
    - Separate user messages and ai messages with a sender-reciever approach. 

 - Work on the backend:
    - Create function to extract key information from accessible docs (i.e the legaldocstest files)
    - Create function to generate documents from extracted data. 
    - Give chatbot privileges to overwrite any of the legal docs. (Not sure how to implement but the current approach I have in mind is to store AI output in a temp file and then replace the old file. This obviously has room for error given that this will extract all the information generated by the chatbot including unwanted boilerplate).
